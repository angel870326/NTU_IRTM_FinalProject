{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM linear, SVM RBF, Adaboost, XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cvaw + stock sign\n",
    "filePath = \"./preprocess/tokens+stockSign/\"\n",
    "df_cvaw_covid = pd.read_csv(filePath + \"cvaw_covid_stockSign.csv\")[[\"Valence_Sum\",\"Arousal_Sum\", \"words_Num\"]]\n",
    "df_cvaw_stock = pd.read_csv(filePath + \"cvaw_stock_stockSign.csv\")[[\"Valence_Sum\",\"Arousal_Sum\", \"words_Num\"]]\n",
    "df_stockSign_covid = pd.read_csv(filePath + \"cvaw_covid_stockSign.csv\")[[\"date\", \"stockRise_mask\", \"stockRise_testKits\", \"stockRise_vaccine\"]]\n",
    "df_stockSign_stock = pd.read_csv(filePath + \"cvaw_stock_stockSign.csv\")[[\"date\", \"stockRise_mask\", \"stockRise_testKits\", \"stockRise_vaccine\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函式：讀 tokens data 並併入情緒詞，切成 x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD_embedding(tokens_name, df_cvaw):\n",
    "    df_embedding = pd.read_csv(\"./TFIDF/\" + tokens_name + \"_stockSign_TFIDF_TruncatedSVD.csv\")\n",
    "    \n",
    "    df_embedding_cvaw = pd.concat([df_embedding, df_cvaw], axis = 1).iloc[:, 1:504]\n",
    "    \n",
    "    x_train, x_test = train_test_split(df_embedding_cvaw, test_size=0.20, random_state=404)\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_embedding(tokens_name, df_cvaw):\n",
    "    df_embedding = pd.read_csv(\"./Word2Vec/\" + tokens_name + \"_stockSign_word2vec.csv\")\n",
    "    \n",
    "    df_embedding_cvaw = pd.concat([df_embedding, df_cvaw], axis = 1).iloc[:, 1:504]\n",
    "    \n",
    "    x_train, x_test = train_test_split(df_embedding_cvaw, test_size=0.20, random_state=404)\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 口罩類股 斷詞 testing & training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mask, x_test_mask = word2vec_embedding(\"covid_token\", df_cvaw_covid)\n",
    "y_train_mask, y_test_mask = train_test_split(df_stockSign_covid[[\"stockRise_mask\"]], test_size=0.20, random_state=404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>Valence_Sum</th>\n",
       "      <th>Arousal_Sum</th>\n",
       "      <th>words_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>0.466977</td>\n",
       "      <td>0.490552</td>\n",
       "      <td>-0.046918</td>\n",
       "      <td>-0.202188</td>\n",
       "      <td>0.166707</td>\n",
       "      <td>0.052072</td>\n",
       "      <td>0.100822</td>\n",
       "      <td>0.127350</td>\n",
       "      <td>0.293276</td>\n",
       "      <td>0.144377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080226</td>\n",
       "      <td>-0.125111</td>\n",
       "      <td>-0.088842</td>\n",
       "      <td>0.191329</td>\n",
       "      <td>-0.090425</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>-0.061873</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-0.137972</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>-0.103087</td>\n",
       "      <td>-0.276188</td>\n",
       "      <td>-0.096632</td>\n",
       "      <td>0.055066</td>\n",
       "      <td>-0.054771</td>\n",
       "      <td>0.103535</td>\n",
       "      <td>-0.027499</td>\n",
       "      <td>0.190077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107904</td>\n",
       "      <td>-0.122517</td>\n",
       "      <td>-0.083494</td>\n",
       "      <td>0.085071</td>\n",
       "      <td>0.077354</td>\n",
       "      <td>0.072515</td>\n",
       "      <td>0.231514</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>-0.272390</td>\n",
       "      <td>-0.219359</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>0.378799</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>-0.015882</td>\n",
       "      <td>-0.218432</td>\n",
       "      <td>0.099289</td>\n",
       "      <td>0.055401</td>\n",
       "      <td>0.247769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022874</td>\n",
       "      <td>0.055691</td>\n",
       "      <td>-0.276878</td>\n",
       "      <td>0.057967</td>\n",
       "      <td>0.295714</td>\n",
       "      <td>-0.024754</td>\n",
       "      <td>0.151208</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>-0.165721</td>\n",
       "      <td>0.238822</td>\n",
       "      <td>-0.049381</td>\n",
       "      <td>-0.021363</td>\n",
       "      <td>0.317870</td>\n",
       "      <td>-0.113444</td>\n",
       "      <td>-0.313132</td>\n",
       "      <td>0.128785</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.069155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234333</td>\n",
       "      <td>-0.128627</td>\n",
       "      <td>0.060161</td>\n",
       "      <td>0.052233</td>\n",
       "      <td>-0.132020</td>\n",
       "      <td>0.074416</td>\n",
       "      <td>0.239536</td>\n",
       "      <td>11.8</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7289</th>\n",
       "      <td>-0.231800</td>\n",
       "      <td>-0.203382</td>\n",
       "      <td>0.166360</td>\n",
       "      <td>-0.131830</td>\n",
       "      <td>0.190765</td>\n",
       "      <td>-0.032649</td>\n",
       "      <td>0.228955</td>\n",
       "      <td>-0.392035</td>\n",
       "      <td>-0.171504</td>\n",
       "      <td>0.106874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069726</td>\n",
       "      <td>-0.126730</td>\n",
       "      <td>0.170638</td>\n",
       "      <td>0.217938</td>\n",
       "      <td>0.494262</td>\n",
       "      <td>0.491883</td>\n",
       "      <td>0.135065</td>\n",
       "      <td>-17.8</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>0.635976</td>\n",
       "      <td>0.370562</td>\n",
       "      <td>-0.194026</td>\n",
       "      <td>-0.273566</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>0.088587</td>\n",
       "      <td>0.273419</td>\n",
       "      <td>0.192486</td>\n",
       "      <td>0.337552</td>\n",
       "      <td>0.173713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.355655</td>\n",
       "      <td>-0.181885</td>\n",
       "      <td>-0.530296</td>\n",
       "      <td>-0.050131</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>-0.168377</td>\n",
       "      <td>-0.005768</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>-0.282629</td>\n",
       "      <td>-0.084010</td>\n",
       "      <td>-0.158663</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>-0.008301</td>\n",
       "      <td>-0.057799</td>\n",
       "      <td>-0.283823</td>\n",
       "      <td>-0.172922</td>\n",
       "      <td>-0.028213</td>\n",
       "      <td>0.138294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076541</td>\n",
       "      <td>-0.203598</td>\n",
       "      <td>-0.086399</td>\n",
       "      <td>-0.062242</td>\n",
       "      <td>-0.176672</td>\n",
       "      <td>-0.209389</td>\n",
       "      <td>0.280768</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>-0.183439</td>\n",
       "      <td>-0.147837</td>\n",
       "      <td>-0.012782</td>\n",
       "      <td>0.516806</td>\n",
       "      <td>-0.024616</td>\n",
       "      <td>-0.445040</td>\n",
       "      <td>0.228963</td>\n",
       "      <td>-0.249978</td>\n",
       "      <td>-0.056679</td>\n",
       "      <td>0.074657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307480</td>\n",
       "      <td>-0.170445</td>\n",
       "      <td>-0.036629</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>0.211082</td>\n",
       "      <td>-0.150104</td>\n",
       "      <td>0.504225</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>0.219891</td>\n",
       "      <td>0.571944</td>\n",
       "      <td>0.013836</td>\n",
       "      <td>-0.294966</td>\n",
       "      <td>0.212134</td>\n",
       "      <td>0.060913</td>\n",
       "      <td>0.161956</td>\n",
       "      <td>-0.021638</td>\n",
       "      <td>0.250821</td>\n",
       "      <td>-0.284589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037604</td>\n",
       "      <td>0.034764</td>\n",
       "      <td>-0.154887</td>\n",
       "      <td>0.087008</td>\n",
       "      <td>-0.282653</td>\n",
       "      <td>-0.279951</td>\n",
       "      <td>-0.046932</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5884</th>\n",
       "      <td>-0.271721</td>\n",
       "      <td>-0.119965</td>\n",
       "      <td>-0.022200</td>\n",
       "      <td>0.173570</td>\n",
       "      <td>-0.233823</td>\n",
       "      <td>-0.198618</td>\n",
       "      <td>0.107825</td>\n",
       "      <td>-0.133190</td>\n",
       "      <td>-0.060561</td>\n",
       "      <td>0.233703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094421</td>\n",
       "      <td>-0.049920</td>\n",
       "      <td>-0.241872</td>\n",
       "      <td>0.105001</td>\n",
       "      <td>0.420913</td>\n",
       "      <td>0.038877</td>\n",
       "      <td>0.244107</td>\n",
       "      <td>-19.2</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6011 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "7271  0.466977  0.490552 -0.046918 -0.202188  0.166707  0.052072  0.100822   \n",
       "317  -0.137972  0.238994 -0.103087 -0.276188 -0.096632  0.055066 -0.054771   \n",
       "1925 -0.272390 -0.219359  0.030242  0.378799  0.014876 -0.015882 -0.218432   \n",
       "3188 -0.165721  0.238822 -0.049381 -0.021363  0.317870 -0.113444 -0.313132   \n",
       "7289 -0.231800 -0.203382  0.166360 -0.131830  0.190765 -0.032649  0.228955   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6031  0.635976  0.370562 -0.194026 -0.273566  0.023036  0.088587  0.273419   \n",
       "5108 -0.282629 -0.084010 -0.158663  0.005067 -0.008301 -0.057799 -0.283823   \n",
       "5302 -0.183439 -0.147837 -0.012782  0.516806 -0.024616 -0.445040  0.228963   \n",
       "5994  0.219891  0.571944  0.013836 -0.294966  0.212134  0.060913  0.161956   \n",
       "5884 -0.271721 -0.119965 -0.022200  0.173570 -0.233823 -0.198618  0.107825   \n",
       "\n",
       "             7         8         9  ...       493       494       495  \\\n",
       "7271  0.127350  0.293276  0.144377  ...  0.080226 -0.125111 -0.088842   \n",
       "317   0.103535 -0.027499  0.190077  ... -0.107904 -0.122517 -0.083494   \n",
       "1925  0.099289  0.055401  0.247769  ... -0.022874  0.055691 -0.276878   \n",
       "3188  0.128785  0.005647  0.069155  ...  0.234333 -0.128627  0.060161   \n",
       "7289 -0.392035 -0.171504  0.106874  ... -0.069726 -0.126730  0.170638   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6031  0.192486  0.337552  0.173713  ... -0.355655 -0.181885 -0.530296   \n",
       "5108 -0.172922 -0.028213  0.138294  ... -0.076541 -0.203598 -0.086399   \n",
       "5302 -0.249978 -0.056679  0.074657  ... -0.307480 -0.170445 -0.036629   \n",
       "5994 -0.021638  0.250821 -0.284589  ...  0.037604  0.034764 -0.154887   \n",
       "5884 -0.133190 -0.060561  0.233703  ... -0.094421 -0.049920 -0.241872   \n",
       "\n",
       "           496       497       498       499  Valence_Sum  Arousal_Sum  \\\n",
       "7271  0.191329 -0.090425  0.034194 -0.061873         -8.4         -5.6   \n",
       "317   0.085071  0.077354  0.072515  0.231514         -4.4        -13.2   \n",
       "1925  0.057967  0.295714 -0.024754  0.151208         -0.6         -3.4   \n",
       "3188  0.052233 -0.132020  0.074416  0.239536         11.8        -10.2   \n",
       "7289  0.217938  0.494262  0.491883  0.135065        -17.8         -2.6   \n",
       "...        ...       ...       ...       ...          ...          ...   \n",
       "6031 -0.050131  0.032169 -0.168377 -0.005768         -1.2        -40.0   \n",
       "5108 -0.062242 -0.176672 -0.209389  0.280768         -5.8         -3.0   \n",
       "5302 -0.077072  0.211082 -0.150104  0.504225          8.6         -5.5   \n",
       "5994  0.087008 -0.282653 -0.279951 -0.046932         -9.3         -5.1   \n",
       "5884  0.105001  0.420913  0.038877  0.244107        -19.2         -7.6   \n",
       "\n",
       "      words_Num  \n",
       "7271          8  \n",
       "317          28  \n",
       "1925          3  \n",
       "3188         17  \n",
       "7289         20  \n",
       "...         ...  \n",
       "6031         56  \n",
       "5108         54  \n",
       "5302         13  \n",
       "5994         12  \n",
       "5884         31  \n",
       "\n",
       "[6011 rows x 503 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mask = x_train_mask.values.tolist()\n",
    "x_test_mask = x_test_mask.values.tolist()\n",
    "y_train_mask = y_train_mask[\"stockRise_mask\"].tolist()\n",
    "y_test_mask = y_test_mask[\"stockRise_mask\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢測試劑類股 斷詞 testing & training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_testKits, x_test_testKits = SVD_embedding(\"stock_token\", df_cvaw_stock)\n",
    "y_train_testKits, y_test_testKits = train_test_split(df_stockSign_stock[[\"stockRise_testKits\"]], test_size=0.20, random_state=404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>Valence_Sum</th>\n",
       "      <th>Arousal_Sum</th>\n",
       "      <th>words_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>0.110194</td>\n",
       "      <td>-0.056617</td>\n",
       "      <td>0.016188</td>\n",
       "      <td>0.051068</td>\n",
       "      <td>0.024915</td>\n",
       "      <td>-0.024274</td>\n",
       "      <td>-0.014723</td>\n",
       "      <td>-0.026258</td>\n",
       "      <td>-0.055791</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.017639</td>\n",
       "      <td>-0.015786</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>0.215222</td>\n",
       "      <td>-0.029807</td>\n",
       "      <td>-0.106440</td>\n",
       "      <td>-0.060623</td>\n",
       "      <td>-0.081690</td>\n",
       "      <td>-0.008828</td>\n",
       "      <td>-0.005497</td>\n",
       "      <td>0.125946</td>\n",
       "      <td>-0.049947</td>\n",
       "      <td>-0.023866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016545</td>\n",
       "      <td>-0.014984</td>\n",
       "      <td>0.025858</td>\n",
       "      <td>-0.018918</td>\n",
       "      <td>-0.001705</td>\n",
       "      <td>0.016183</td>\n",
       "      <td>0.027335</td>\n",
       "      <td>35.6</td>\n",
       "      <td>-22.2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>0.190443</td>\n",
       "      <td>0.456539</td>\n",
       "      <td>-0.089589</td>\n",
       "      <td>0.113550</td>\n",
       "      <td>0.085209</td>\n",
       "      <td>-0.011482</td>\n",
       "      <td>-0.013740</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>-0.076117</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018082</td>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>-0.022592</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.007836</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-12.4</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>0.230840</td>\n",
       "      <td>-0.021076</td>\n",
       "      <td>-0.092870</td>\n",
       "      <td>-0.061819</td>\n",
       "      <td>-0.110322</td>\n",
       "      <td>-0.008187</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.030462</td>\n",
       "      <td>0.027457</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>-0.002002</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.010414</td>\n",
       "      <td>-0.025819</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>0.153676</td>\n",
       "      <td>-0.052038</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>0.192235</td>\n",
       "      <td>0.037284</td>\n",
       "      <td>-0.009671</td>\n",
       "      <td>0.023961</td>\n",
       "      <td>0.167582</td>\n",
       "      <td>-0.376188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.005709</td>\n",
       "      <td>0.024119</td>\n",
       "      <td>-0.035278</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>-0.016911</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>0.114674</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>-0.026531</td>\n",
       "      <td>-0.063207</td>\n",
       "      <td>0.020567</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>0.034781</td>\n",
       "      <td>-0.019504</td>\n",
       "      <td>-0.047736</td>\n",
       "      <td>0.029909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007536</td>\n",
       "      <td>0.015456</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.019762</td>\n",
       "      <td>-0.006434</td>\n",
       "      <td>-0.001645</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>0.140593</td>\n",
       "      <td>-0.014271</td>\n",
       "      <td>-0.065399</td>\n",
       "      <td>-0.031681</td>\n",
       "      <td>-0.076528</td>\n",
       "      <td>-0.009261</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.053130</td>\n",
       "      <td>-0.032995</td>\n",
       "      <td>-0.036033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045533</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>-0.019156</td>\n",
       "      <td>-0.023624</td>\n",
       "      <td>50.5</td>\n",
       "      <td>-27.6</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>0.080773</td>\n",
       "      <td>-0.011286</td>\n",
       "      <td>0.018688</td>\n",
       "      <td>0.016437</td>\n",
       "      <td>-0.017477</td>\n",
       "      <td>-0.009216</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.032430</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.047174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>-0.012008</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>-0.005537</td>\n",
       "      <td>0.018533</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5884</th>\n",
       "      <td>0.158278</td>\n",
       "      <td>0.128662</td>\n",
       "      <td>-0.078809</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>-0.018054</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>-0.067082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>-0.010579</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>-0.008569</td>\n",
       "      <td>0.012491</td>\n",
       "      <td>-0.017333</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>0.089186</td>\n",
       "      <td>-0.013863</td>\n",
       "      <td>0.013187</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>-0.007844</td>\n",
       "      <td>-0.026448</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>-0.009380</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>-0.030506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>-0.010593</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>-0.013806</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-14.2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7783 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "6004  0.110194 -0.056617  0.016188  0.051068  0.024915 -0.024274 -0.014723   \n",
       "6702  0.215222 -0.029807 -0.106440 -0.060623 -0.081690 -0.008828 -0.005497   \n",
       "4971  0.190443  0.456539 -0.089589  0.113550  0.085209 -0.011482 -0.013740   \n",
       "1867  0.230840 -0.021076 -0.092870 -0.061819 -0.110322 -0.008187  0.002349   \n",
       "2484  0.153676 -0.052038  0.060150  0.017483  0.192235  0.037284 -0.009671   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6031  0.114674  0.005346 -0.026531 -0.063207  0.020567  0.034371  0.034781   \n",
       "5108  0.140593 -0.014271 -0.065399 -0.031681 -0.076528 -0.009261  0.001531   \n",
       "5302  0.080773 -0.011286  0.018688  0.016437 -0.017477 -0.009216 -0.000077   \n",
       "5884  0.158278  0.128662 -0.078809  0.024062  0.000665 -0.018054  0.009116   \n",
       "7911  0.089186 -0.013863  0.013187  0.007128 -0.007844 -0.026448  0.001017   \n",
       "\n",
       "             7         8         9  ...       493       494       495  \\\n",
       "6004 -0.026258 -0.055791 -0.005208  ...  0.003994  0.017639 -0.015786   \n",
       "6702  0.125946 -0.049947 -0.023866  ... -0.016545 -0.014984  0.025858   \n",
       "4971  0.040625 -0.076117  0.018417  ... -0.018082  0.016909  0.012102   \n",
       "1867  0.030462  0.027457  0.002368  ...  0.010719 -0.002002  0.002424   \n",
       "2484  0.023961  0.167582 -0.376188  ...  0.012238 -0.005709  0.024119   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6031 -0.019504 -0.047736  0.029909  ... -0.007536  0.015456  0.012212   \n",
       "5108  0.053130 -0.032995 -0.036033  ...  0.045533  0.011390  0.017935   \n",
       "5302 -0.032430  0.000492  0.047174  ...  0.004887 -0.012008  0.003088   \n",
       "5884  0.010543  0.001331 -0.067082  ...  0.008776 -0.010579  0.002256   \n",
       "7911 -0.009380 -0.002694 -0.030506  ...  0.016993  0.003443 -0.010593   \n",
       "\n",
       "           496       497       498       499  Valence_Sum  Arousal_Sum  \\\n",
       "6004  0.002318  0.026095  0.000526  0.005658          3.0         -2.6   \n",
       "6702 -0.018918 -0.001705  0.016183  0.027335         35.6        -22.2   \n",
       "4971  0.003540 -0.022592  0.000633 -0.007836         14.0        -12.4   \n",
       "1867  0.010414 -0.025819  0.006383  0.013708          8.2        -33.6   \n",
       "2484 -0.035278  0.012393 -0.016911  0.011092          0.1        -15.9   \n",
       "...        ...       ...       ...       ...          ...          ...   \n",
       "6031  0.022440  0.019762 -0.006434 -0.001645         -5.5          6.6   \n",
       "5108  0.011710  0.002624 -0.019156 -0.023624         50.5        -27.6   \n",
       "5302  0.024134  0.012363 -0.005537  0.018533          3.6         -5.8   \n",
       "5884 -0.008569  0.012491 -0.017333 -0.002944         12.6        -25.0   \n",
       "7911  0.000378  0.005904 -0.013806  0.009312          1.8        -14.2   \n",
       "\n",
       "      words_Num  \n",
       "6004         12  \n",
       "6702         48  \n",
       "4971         29  \n",
       "1867         39  \n",
       "2484         35  \n",
       "...         ...  \n",
       "6031         18  \n",
       "5108         57  \n",
       "5302         13  \n",
       "5884         39  \n",
       "7911         40  \n",
       "\n",
       "[7783 rows x 503 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_testKits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_testKits = x_train_testKits.values.tolist()\n",
    "x_test_testKits = x_test_testKits.values.tolist()\n",
    "y_train_testKits = y_train_testKits[\"stockRise_testKits\"].tolist()\n",
    "y_test_testKits = y_test_testKits[\"stockRise_testKits\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 疫苗類股 斷詞 testing & training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vaccine, x_test_vaccine = SVD_embedding(\"stock_token\", df_cvaw_stock)\n",
    "y_train_vaccine, y_test_vaccine = train_test_split(df_stockSign_stock[[\"stockRise_vaccine\"]], test_size=0.20, random_state=404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockRise_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5884</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7783 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stockRise_vaccine\n",
       "6004                  0\n",
       "6702                 -1\n",
       "4971                  0\n",
       "1867                  0\n",
       "2484                  0\n",
       "...                 ...\n",
       "6031                  0\n",
       "5108                  0\n",
       "5302                  1\n",
       "5884                  0\n",
       "7911                  1\n",
       "\n",
       "[7783 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vaccine = x_train_vaccine.values.tolist()\n",
    "x_test_vaccine = x_test_vaccine.values.tolist()\n",
    "y_train_vaccine = y_train_vaccine[\"stockRise_vaccine\"].tolist()\n",
    "y_test_vaccine = y_test_vaccine[\"stockRise_vaccine\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model 函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_predict_stocks(x_train, y_train, x_test, y_test, tokens_name, predict_stocks_name, Linear, embedding):\n",
    "    \n",
    "    if Linear == True:\n",
    "        SVM_model = SVC(kernel = \"linear\", C = 1.0, probability=True)\n",
    "    else:\n",
    "        SVM_model = SVC(kernel = \"rbf\", gamma = \"scale\", C = 1.0, probability=True)\n",
    "    \n",
    "    t0 = time()\n",
    "    SVM_model.fit(x_train, y_train)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "    \n",
    "    predicted_results = []\n",
    "    excepted_results = []\n",
    "\n",
    "    excepted_results.extend(y_test)\n",
    "    predicted_results.extend(SVM_model.predict(x_test))\n",
    "    \n",
    "    if Linear == True:\n",
    "        print(tokens_name + \" predict \" + predict_stocks_name + \"(SVM Linear + \" + embedding + \")\")\n",
    "    else:\n",
    "        print(tokens_name + \" predict \" + predict_stocks_name + \"(SVM RBF + \" + embedding + \")\")\n",
    "        \n",
    "    print(metrics.classification_report(excepted_results,predicted_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost model 函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_tokens_predict_stocks(x_train, y_train, x_test, y_test, tokens_name, predict_stocks_name, embedding, n_estimator):\n",
    "    \n",
    "    adaboost_model = AdaBoostClassifier(n_estimators = n_estimator, random_state = 404)\n",
    "    \n",
    "    t0 = time()\n",
    "    adaboost_model.fit(x_train, y_train)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "    \n",
    "    predicted_results = []\n",
    "    excepted_results = []\n",
    "\n",
    "    excepted_results.extend(y_test)\n",
    "    predicted_results.extend(adaboost_model.predict(x_test))\n",
    "\n",
    "    print(tokens_name + \" predict \" + predict_stocks_name + \"(adaboost + \" + embedding + \")\")\n",
    "        \n",
    "    print(metrics.classification_report(excepted_results,predicted_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost model 函式（train, test 不能轉為 list）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_tokens_predict_stocks(x_train, y_train, x_test, y_test, tokens_name, predict_stocks_name, embedding, stock_type):\n",
    "    \n",
    "    y_test = y_test[\"stockRise_\" + stock_type].tolist()\n",
    "    \n",
    "    xgboost_model = XGBClassifier(random_state = 404)\n",
    "    \n",
    "    t0 = time()\n",
    "    xgboost_model.fit(x_train, y_train)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "    \n",
    "    predicted_results = []\n",
    "    excepted_results = []\n",
    "\n",
    "    excepted_results.extend(y_test)\n",
    "    predicted_results.extend(xgboost_model.predict(x_test))\n",
    "\n",
    "    print(tokens_name + \" predict \" + predict_stocks_name + \"(xgboost + \" + embedding + \")\")\n",
    "        \n",
    "    print(metrics.classification_report(excepted_results,predicted_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測口罩類股漲跌效果（word2vec covid 板 ckip 斷詞）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1539.784s.\n",
      "Covid CKIP token predict mask stock(SVM Linear + word2vec)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.49      0.44       557\n",
      "           0       0.00      0.00      0.00       324\n",
      "           1       0.44      0.57      0.49       622\n",
      "\n",
      "    accuracy                           0.42      1503\n",
      "   macro avg       0.28      0.35      0.31      1503\n",
      "weighted avg       0.33      0.42      0.37      1503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tokens_predict_stocks(x_train_mask, y_train_mask, x_test_mask, y_test_mask, \"Covid CKIP token\", \"mask stock\", True, \"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 181.131s.\n",
      "Covid CKIP token predict mask stock(SVM RBF + word2vec)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.36      0.36      0.36       557\n",
      "           0       0.00      0.00      0.00       324\n",
      "           1       0.43      0.66      0.52       622\n",
      "\n",
      "    accuracy                           0.40      1503\n",
      "   macro avg       0.26      0.34      0.29      1503\n",
      "weighted avg       0.31      0.40      0.35      1503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tokens_predict_stocks(x_train_mask, y_train_mask, x_test_mask, y_test_mask, \"Covid CKIP token\", \"mask stock\", False, \"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 40.591s.\n",
      "Covid CKIP token predict mask stock(adaboost + word2vec)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      0.42      0.40       557\n",
      "           0       0.29      0.18      0.22       324\n",
      "           1       0.43      0.48      0.45       622\n",
      "\n",
      "    accuracy                           0.39      1503\n",
      "   macro avg       0.37      0.36      0.36      1503\n",
      "weighted avg       0.38      0.39      0.38      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_tokens_predict_stocks(x_train_mask, y_train_mask, x_test_mask, y_test_mask, \"Covid CKIP token\", \"mask stock\", \"word2vec\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\molly\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:20:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "done in 148.852s.\n",
      "Covid CKIP token predict mask stock(xgboost + word2vec)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.46      0.43       557\n",
      "           0       0.26      0.13      0.17       324\n",
      "           1       0.43      0.50      0.47       622\n",
      "\n",
      "    accuracy                           0.40      1503\n",
      "   macro avg       0.37      0.36      0.35      1503\n",
      "weighted avg       0.39      0.40      0.39      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost_tokens_predict_stocks(x_train_mask, y_train_mask, x_test_mask, y_test_mask, \"Covid CKIP token\", \"mask stock\", \"word2vec\", \"mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測檢測試劑類股漲跌效果（SVD stock 板 jieba 斷詞）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 685.249s.\n",
      "Stock jieba token predict testKits stock(SVM Linear + SVD vector)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.43      0.07      0.12       525\n",
      "           0       0.45      0.94      0.61       855\n",
      "           1       0.28      0.03      0.06       566\n",
      "\n",
      "    accuracy                           0.44      1946\n",
      "   macro avg       0.38      0.35      0.26      1946\n",
      "weighted avg       0.39      0.44      0.32      1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_predict_stocks(x_train_testKits, y_train_testKits, x_test_testKits, y_test_testKits, \"Stock jieba token\", \"testKits stock\", True, \"SVD vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 286.804s.\n",
      "Stock jieba token predict testKits stock(SVM RBF + SVD vector)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       525\n",
      "           0       0.44      0.99      0.61       855\n",
      "           1       0.00      0.00      0.00       566\n",
      "\n",
      "    accuracy                           0.44      1946\n",
      "   macro avg       0.15      0.33      0.20      1946\n",
      "weighted avg       0.19      0.44      0.27      1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_predict_stocks(x_train_testKits, y_train_testKits, x_test_testKits, y_test_testKits, \"Stock jieba token\", \"testKits stock\", False, \"SVD vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 54.170s.\n",
      "Stock jieba token predict testKits stock(adaboost + SVD vector)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.30      0.24      0.27       525\n",
      "           0       0.46      0.63      0.53       855\n",
      "           1       0.31      0.21      0.25       566\n",
      "\n",
      "    accuracy                           0.40      1946\n",
      "   macro avg       0.36      0.36      0.35      1946\n",
      "weighted avg       0.38      0.40      0.38      1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_tokens_predict_stocks(x_train_testKits, y_train_testKits, x_test_testKits, y_test_testKits, \"Stock jieba token\", \"testKits stock\", \"SVD vector\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:22:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "done in 121.693s.\n",
      "Stock jieba token predict testKits stock(xgboost + SVD vector)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      0.24      0.29       525\n",
      "           0       0.49      0.66      0.56       855\n",
      "           1       0.35      0.27      0.30       566\n",
      "\n",
      "    accuracy                           0.43      1946\n",
      "   macro avg       0.40      0.39      0.38      1946\n",
      "weighted avg       0.41      0.43      0.41      1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost_tokens_predict_stocks(x_train_testKits, y_train_testKits, x_test_testKits, y_test_testKits, \"Stock jieba token\", \"testKits stock\", \"SVD vector\", \"testKits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測疫苗類股漲跌效果（SVD stock 板 jieba 斷詞）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2486.373s.\n",
      "Stock jieba token predict vaccine stock(SVM Linear + SVD vector)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.12      0.00      0.01       428\n",
      "           0       0.56      0.99      0.72      1082\n",
      "           1       0.75      0.01      0.01       436\n",
      "\n",
      "    accuracy                           0.56      1946\n",
      "   macro avg       0.48      0.34      0.25      1946\n",
      "weighted avg       0.51      0.56      0.40      1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_predict_stocks(x_train_vaccine, y_train_vaccine, x_test_vaccine, y_test_vaccine, \"Stock jieba token\", \"vaccine stock\", True, \"SVD vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 233.201s.\n",
      "Stock jieba token predict vaccine stock(SVM RBF + SVD vector)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       428\n",
      "           0       0.56      1.00      0.71      1082\n",
      "           1       0.00      0.00      0.00       436\n",
      "\n",
      "    accuracy                           0.56      1946\n",
      "   macro avg       0.19      0.33      0.24      1946\n",
      "weighted avg       0.31      0.56      0.40      1946\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tokens_predict_stocks(x_train_vaccine, y_train_vaccine, x_test_vaccine, y_test_vaccine, \"Stock jieba token\", \"vaccine stock\", False, \"SVD vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 55.273s.\n",
      "Stock jieba token predict vaccine stock(adaboost + SVD vector)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.23      0.08      0.12       428\n",
      "           0       0.57      0.86      0.69      1082\n",
      "           1       0.25      0.09      0.13       436\n",
      "\n",
      "    accuracy                           0.52      1946\n",
      "   macro avg       0.35      0.34      0.31      1946\n",
      "weighted avg       0.42      0.52      0.44      1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_tokens_predict_stocks(x_train_vaccine, y_train_vaccine, x_test_vaccine, y_test_vaccine, \"Stock jieba token\", \"vaccine stock\", \"SVD vector\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:24:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "done in 96.720s.\n",
      "Stock jieba token predict vaccine stock(xgboost + SVD vector)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.31      0.09      0.14       428\n",
      "           0       0.58      0.92      0.71      1082\n",
      "           1       0.32      0.09      0.14       436\n",
      "\n",
      "    accuracy                           0.55      1946\n",
      "   macro avg       0.40      0.37      0.33      1946\n",
      "weighted avg       0.46      0.55      0.46      1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost_tokens_predict_stocks(x_train_vaccine, y_train_vaccine, x_test_vaccine, y_test_vaccine, \"Stock jieba token\", \"vaccine stock\", \"SVD vector\", \"vaccine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
